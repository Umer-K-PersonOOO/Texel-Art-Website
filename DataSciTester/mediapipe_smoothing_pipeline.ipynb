{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b407a52f",
   "metadata": {},
   "source": [
    "# Non-Blender MediaPipe Landmark Smoothing Pipeline\n",
    "\n",
    "This jupyter notebook is for those who are trying to get started and what a simple view of what we are doing. This removes all the blender aspects of the project, and is a space to test diffrent algos. Before you begin, make sure to pip install:\n",
    "- Mediapipe\n",
    "- cv2\n",
    "\n",
    "## 1. Pre-clean (whole-sequence pass)\n",
    "- Normalize all landmarks to a consistent coordinate space.\n",
    "- Reject or drop extreme spikes (e.g., velocity z-score across the sequence).\n",
    "- Fill gaps from dropped frames with linear or spline interpolation.\n",
    "\n",
    "## 2. Temporal denoising (window/full sequence) [Try this one!]\n",
    "- **Savitzky–Golay filter** (window 7–11 frames, polynomial order 2) — smooths while keeping peaks sharp. (https://eigenvector.com/wp-content/uploads/2020/01/SavitzkyGolay.pdf)\n",
    "- Or apply a **low-pass Butterworth/IIR filter** to each joint trajectory.  \n",
    "Both require larger windows or the full trajectory to avoid introducing lag.\n",
    "\n",
    "## 3. Adaptive pass (optional)\n",
    "- Run a **One-Euro filter** tuned on the cleaned signal.  \n",
    "Since we have full data, apply it forward **and** backward (causal + anti-causal) to cancel lag.\n",
    "\n",
    "## 4. Kalman smoothing (not just filtering)\n",
    "- Instead of online Kalman, run a full **Rauch–Tung–Striebel smoother** per joint. (https://arxiv.org/pdf/1303.5237)\n",
    "This backward pass bridges dropouts and reduces jitter more than the real-time Kalman filter.\n",
    "\n",
    "## 6. Orientation smoothing\n",
    "- Smooth orientations using **SLERP with EMA/One-Euro** across the whole sequence. (https://direction.bordeaux.inria.fr/~roussel/publications/2012-CHI-one-euro-filter.pdf)\n",
    "\n",
    "## 7. Rig-side polish\n",
    "- Add velocity/acceleration penalties during retarget optimization.\n",
    "- After baking to the rig, apply a final **low-pass filter (e.g. 2nd-order Butterworth, cutoff 6–8 Hz @30 fps)** on Euler f-curves.\n",
    "- Don't worry about this though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29548625-00e0-4962-990e-ff741f32389e",
   "metadata": {},
   "source": [
    "## Globals and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec38ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SOURCE = \"webcam\" # options are webcam or video\n",
    "VIDEO_PATH = \"sample.mp4\"\n",
    "WEBCAM_ID = 0 # IF YOU GET A WEBCAM ERROR SWITCH THIS NUMBER\n",
    "DRAW_2D = True # Turn off if you don't care about cv2 output (most helpful for video output).\n",
    "COLLECT_FRAMES = True\n",
    "MAX_FRAMES = None\n",
    "SAVE_PREFIX = \"pose_run\"\n",
    "\n",
    "import cv2, time, json, numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b41e0-3885-4372-92d2-c4280dba10b5",
   "metadata": {},
   "source": [
    "## Main fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba5a35bd-2c25-421c-8af1-283a41396429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about this function.\n",
    "def open_capture():\n",
    "    if INPUT_SOURCE == \"video\":\n",
    "        cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "        if not cap.isOpened():\n",
    "            raise FileNotFoundError(f\"Could not open: {VIDEO_PATH}\")\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(WEBCAM_ID)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "        if fps < 1: fps = 30.0\n",
    "    return cap, float(fps)\n",
    "\n",
    "class PoseRunner:\n",
    "    def __init__(self):\n",
    "        self.pose = mp.solutions.pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=2,\n",
    "            smooth_landmarks=True,\n",
    "            min_detection_confidence=0.6,\n",
    "            min_tracking_confidence=0.75\n",
    "        )\n",
    "        self.conn = mp.solutions.pose.POSE_CONNECTIONS\n",
    "        self.N = 33  # pose landmarks\n",
    "\n",
    "    def process(self, bgr):\n",
    "        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        res = self.pose.process(rgb)\n",
    "\n",
    "        pts2d = None\n",
    "        if res.pose_landmarks:\n",
    "            pts2d = np.array([(lm.x, lm.y, lm.z, lm.visibility)\n",
    "                              for lm in res.pose_landmarks.landmark],\n",
    "                             dtype=np.float32)  # (33,4)\n",
    "\n",
    "        pts3d = None\n",
    "        if res.pose_world_landmarks:\n",
    "            pts3d = np.array([(lm.x, lm.y, lm.z, lm.visibility)\n",
    "                              for lm in res.pose_world_landmarks.landmark],\n",
    "                             dtype=np.float32)  # (33,4)\n",
    "\n",
    "        return pts2d, pts3d\n",
    "\n",
    "    def close(self): self.pose.close()\n",
    "\n",
    "\n",
    "# This is where most of the chagnes are going to be implemented\n",
    "class IdentitySmoother:\n",
    "    \"\"\"\n",
    "    Skeleton smoother. Replace `step` contents later with EMA / One-Euro / Kalman.\n",
    "    Keeps shapes and API stable so you can drop in your logic.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._last = None\n",
    "\n",
    "    def step(self, t, pts: np.ndarray) -> np.ndarray:\n",
    "        return pts\n",
    "\n",
    "# No need to worry about this function this is just for a live view of the output.\n",
    "def draw_points_and_bones(frame_bgr, pts_2d: np.ndarray, connections, color=(0,255,0)):\n",
    "    if pts_2d is None: return frame_bgr\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if connections:\n",
    "        for a, b in connections:\n",
    "            xa, ya = int(pts_2d[a,0]*W), int(pts_2d[a,1]*H)\n",
    "            xb, yb = int(pts_2d[b,0]*W), int(pts_2d[b,1]*H)\n",
    "            if 0 <= xa < W and 0 <= ya < H and 0 <= xb < W and 0 <= yb < H:\n",
    "                if pts_2d[a,3] > 0.2 and pts_2d[b,3] > 0.2:\n",
    "                    cv2.line(frame_bgr, (xa,ya), (xb,yb), color, 2, cv2.LINE_AA)\n",
    "    for (x,y,_,vis) in pts_2d:\n",
    "        if vis <= 0.2: continue\n",
    "        cx, cy = int(x*W), int(y*H)\n",
    "        if 0 <= cx < W and 0 <= cy < H:\n",
    "            cv2.circle(frame_bgr, (cx,cy), 3, color, -1, cv2.LINE_AA)\n",
    "    return frame_bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf87fc-fa56-4ba4-b626-8f093f738d94",
   "metadata": {},
   "source": [
    "## Runner Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4b5d2fd-874b-4c22-a42f-c564246b3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at ~10.0 FPS — press 'q' to quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757635477.540333   18979 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1757635477.542747   47686 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1~bpo12+1pop1~1744225826~22.04~b077665), renderer: Mesa Intel(R) Graphics (ADL GT2)\n",
      "W0000 00:00:1757635477.627206   47667 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1757635477.768828   47665 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packed arrays:\n",
      " raw2d: (103, 33, 4)  raw3d: (103, 33, 4)  sm2d: (103, 33, 4)  sm3d: (103, 33, 4)\n",
      "Saved:\n",
      "  pose_run_raw.npz\n",
      "  pose_run_smooth.npz\n",
      "  pose_run_meta.json\n"
     ]
    }
   ],
   "source": [
    "cap, fps = open_capture()\n",
    "pose = PoseRunner()\n",
    "filt2d, filt3d = IdentitySmoother(), IdentitySmoother()\n",
    "\n",
    "raw2d_list, raw3d_list = [], []\n",
    "sm2d_list,  sm3d_list  = [], []\n",
    "times = []\n",
    "\n",
    "t0, frame_idx = time.time(), 0\n",
    "print(f\"Running at ~{fps:.1f} FPS — press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ok, bgr = cap.read()\n",
    "    if not ok: break\n",
    "    frame_idx += 1\n",
    "    if (MAX_FRAMES is not None) and (frame_idx > MAX_FRAMES): break\n",
    "\n",
    "    pts2d, pts3d = pose.process(bgr)\n",
    "    t = time.time() - t0\n",
    "\n",
    "    raw2d_list.append(pts2d.copy() if pts2d is not None else None)\n",
    "    raw3d_list.append(pts3d.copy() if pts3d is not None else None)\n",
    "\n",
    "    sm2d = filt2d.step(t, pts2d) if pts2d is not None else None\n",
    "    sm3d = filt3d.step(t, pts3d) if pts3d is not None else None\n",
    "    sm2d_list.append(sm2d.copy() if sm2d is not None else None)\n",
    "    sm3d_list.append(sm3d.copy() if sm3d is not None else None)\n",
    "    times.append(t)\n",
    "\n",
    "    if DRAW_2D:\n",
    "        vis = bgr.copy()\n",
    "        if sm2d is not None:\n",
    "            vis = draw_points_and_bones(vis, sm2d, pose.conn, color=(0,255,0))\n",
    "        cv2.putText(vis, f\"Frame {frame_idx}\", (12,26),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"MediaPipe Pose - Stored Raw & Filtered\", vis)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release(); pose.close(); cv2.destroyAllWindows()\n",
    "\n",
    "T, N = len(times), pose.N\n",
    "def stack_or_nan(seq, N):\n",
    "    \"\"\"Pack list[None or (N,4)] -> (T,N,4) with NaNs for missing frames.\"\"\"\n",
    "    out = np.full((T, N, 4), np.nan, dtype=np.float32)\n",
    "    for i, arr in enumerate(seq):\n",
    "        if arr is None: continue\n",
    "        if arr.shape == (N,4):\n",
    "            out[i] = arr\n",
    "    return out\n",
    "\n",
    "raw2d = stack_or_nan(raw2d_list, N)\n",
    "raw3d = stack_or_nan(raw3d_list, N)\n",
    "sm2d  = stack_or_nan(sm2d_list,  N)\n",
    "sm3d  = stack_or_nan(sm3d_list,  N)\n",
    "\n",
    "print(\"Packed arrays:\")\n",
    "print(\" raw2d:\", raw2d.shape, \" raw3d:\", raw3d.shape, \" sm2d:\", sm2d.shape, \" sm3d:\", sm3d.shape)\n",
    "\n",
    "np.savez_compressed(f\"{SAVE_PREFIX}_raw.npz\",\n",
    "                    times=np.array(times, dtype=np.float32),\n",
    "                    pose2d=raw2d, pose3d=raw3d)\n",
    "np.savez_compressed(f\"{SAVE_PREFIX}_smooth.npz\",\n",
    "                    times=np.array(times, dtype=np.float32),\n",
    "                    pose2d=sm2d,  pose3d=sm3d)\n",
    "\n",
    "meta = {\n",
    "    \"source\": INPUT_SOURCE if INPUT_SOURCE==\"webcam\" else os.path.abspath(VIDEO_PATH),\n",
    "    \"fps\": fps,\n",
    "    \"num_frames\": T,\n",
    "    \"landmarks\": \"MediaPipe Pose (33 points, columns: x,y,z,visibility)\",\n",
    "    \"shapes\": {\n",
    "        \"raw2d\":  raw2d.shape,\n",
    "        \"raw3d\":  raw3d.shape,\n",
    "        \"sm2d\":   sm2d.shape,\n",
    "        \"sm3d\":   sm3d.shape\n",
    "    }\n",
    "}\n",
    "with open(f\"{SAVE_PREFIX}_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(f\"Saved:\\n  {SAVE_PREFIX}_raw.npz\\n  {SAVE_PREFIX}_smooth.npz\\n  {SAVE_PREFIX}_meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0df3a-e18f-4295-a3fa-6be195aa123f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
